{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "pix2pix.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mnansary/pyF2O/blob/master/colab_gen_unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1ojVYZ7Spzpv"
      },
      "source": [
        "# colab specific task\n",
        "*   Check TF version\n",
        "*   mount google drive\n",
        "*   TPU check\n",
        "*   Change Working Directory to cloned dir \n",
        "\n",
        "NOTE: **git clone the repo before running this notebook**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5-LGC4qPKhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install tensorflow==1.14.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "--q4JaV2ps6z",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9NVN35lELc_p",
        "colab": {}
      },
      "source": [
        "\n",
        "# tpu check\n",
        "import os\n",
        "import pprint\n",
        "import tensorflow as tf\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "    devices = session.list_devices()\n",
        "    \n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(devices)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM0M9272Lafp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHqKojwYNT58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/gdrive/My\\ Drive/PROJECTS/F2O/pyF2O/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_HoJM2SopemQ"
      },
      "source": [
        "# GCS specific task \n",
        "* **auth user**\n",
        "* **save** and **upload** credentials to **tpu**\n",
        "* set project information\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cAxBhxEtlLm9",
        "colab": {}
      },
      "source": [
        "# auth user for cloud SDK\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O-JJkYZILgmi",
        "colab": {}
      },
      "source": [
        "# Save credentials\n",
        "import json\n",
        "SERVICE_KEY_PATH='/content/adc.json' # @param\n",
        "# Upload credentials to TPU.\n",
        "with tf.Session(TPU_ADDRESS) as sess:    \n",
        "    with open(SERVICE_KEY_PATH, 'r') as f:\n",
        "        auth_info = json.load(f)\n",
        "        tf.contrib.cloud.configure_gcs(sess, credentials=auth_info)\n",
        "# set service_account\n",
        "JSON_DATA=json.load(open(SERVICE_KEY_PATH))\n",
        "SERVICE_ACCOUNT=str(JSON_DATA['client_id']).split('.')[0]\n",
        "print('Service Account:',SERVICE_ACCOUNT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E0MQ_8RgO4Qi"
      },
      "source": [
        "#### SET PROJECT INFORMATION "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4pCaaRGjLRmz",
        "colab": {}
      },
      "source": [
        "PROJECT_ID    ='f2oitpu'               # @param \n",
        "BUCKET        ='f2odata'               # @param \n",
        "\n",
        "# LIST FILES\n",
        "TFRECORDS_DIR= 'gs://{}/{}/'.format(BUCKET,'tfrecord')\n",
        "MODEL_DIR    = 'gs://{}/{}/'.format(BUCKET,'model_dir')\n",
        "# change TFRECORDS_DIR specific to structre\n",
        "#\n",
        "!gcloud config set project {PROJECT_ID}\n",
        "!gsutil ls {TFRECORDS_DIR}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dxefiHZ4qlHA"
      },
      "source": [
        "# pix2pix\n",
        "* set **FLAGS** \n",
        "* define **model function**\n",
        "* define **input function**\n",
        "* define **config**\n",
        "* define **estimator**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FRPtSIGWin7u"
      },
      "source": [
        "#### FLAGS AND PARAMS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BOro7D1krWYf",
        "colab": {}
      },
      "source": [
        "class FLAGS:\n",
        "    IMAGE_DIM       = 256       # @param\n",
        "    NB_CHANNELS     = 3         # @param\n",
        "    BATCH_SIZE      = 128       # @param\n",
        "    SHUFFLE_BUFFER  = 1000      # @param    \n",
        "    NB_TOTAL_DATA   = 16128     # @param\n",
        "    NB_EVAL_DATA    = 3200      # @param\n",
        "    ITERATIONS      = 500       # @param\n",
        "    LEARNING_RATE   = 0.0002    # @param\n",
        "\n",
        "MODEL_EXPORT_NAME = 'f20-pix2pix' # @param\n",
        "STEPS           = FLAGS.NB_TOTAL_DATA // FLAGS.BATCH_SIZE \n",
        "print('Num of Steps:{}'.format(STEPS))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQO3uJ6KN3W3",
        "colab_type": "text"
      },
      "source": [
        "#### Model Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZb95zZjN_yu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from F2O.pix2pix import loss_fn\n",
        "\n",
        "def model_fn(features, labels, mode, params):\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        raise RuntimeError(\"mode {} is not supported yet\".format(mode))\n",
        "\n",
        "    loss = loss_fn(features, labels)\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        learning_rate = tf.train.exponential_decay(\n",
        "                                    FLAGS.LEARNING_RATE,\n",
        "                                    tf.train.get_global_step(),\n",
        "                                    decay_steps=100000,\n",
        "                                    decay_rate=0.96\n",
        "                        )\n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "        optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\n",
        "\n",
        "        return tf.contrib.tpu.TPUEstimatorSpec(\n",
        "                                                mode=mode,\n",
        "                                                loss=loss,\n",
        "                                                train_op=optimizer.minimize(\n",
        "                                                    loss, \n",
        "                                                    tf.train.get_global_step()\n",
        "                                                    )\n",
        "                                              )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6C3FkEX-iu9n"
      },
      "source": [
        "#### Data Input Functions\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yjBH4t36PydC",
        "colab": {}
      },
      "source": [
        "from google.cloud import storage\n",
        "from functools import partial\n",
        "\n",
        "client = storage.Client(PROJECT_ID)\n",
        "# get bucket from the project\n",
        "bucket=client.get_bucket(BUCKET)\n",
        "print(bucket)\n",
        "\n",
        "def data_input_fn(FLAGS,params): \n",
        "    \n",
        "    def _parser(example):\n",
        "        feature ={  'image'  : tf.io.FixedLenFeature([],tf.string) ,\n",
        "                    'target' : tf.io.FixedLenFeature([],tf.string)\n",
        "        }    \n",
        "        parsed_example=tf.io.parse_single_example(example,feature)\n",
        "        image_raw=parsed_example['image']\n",
        "        image=tf.image.decode_png(image_raw,channels=FLAGS.NB_CHANNELS)\n",
        "        image=tf.cast(image,tf.float32)/255.0\n",
        "        image=tf.reshape(image,(FLAGS.IMAGE_DIM,FLAGS.IMAGE_DIM,FLAGS.NB_CHANNELS))\n",
        "        \n",
        "        target_raw=parsed_example['target']\n",
        "        target=tf.image.decode_png(target_raw,channels=FLAGS.NB_CHANNELS)\n",
        "        target=tf.cast(target,tf.float32)/255.0\n",
        "        target=tf.reshape(target,(FLAGS.IMAGE_DIM,FLAGS.IMAGE_DIM,FLAGS.NB_CHANNELS))\n",
        "        \n",
        "        return image,target\n",
        "\n",
        "    #dataset = tf.data.TFRecordDataset([os.path.join('gs://{}/'.format(BUCKET), f.name) for f in bucket.list_blobs(prefix='tfrecord/{}'.format(mode))])\n",
        "    dataset = tf.data.TFRecordDataset([os.path.join('gs://{}/'.format(BUCKET), f.name) for f in bucket.list_blobs()])\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.shuffle(FLAGS.SHUFFLE_BUFFER,reshuffle_each_iteration=True)\n",
        "    dataset = dataset.map(_parser)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(FLAGS.BATCH_SIZE,drop_remainder=True)\n",
        "    dataset = dataset.prefetch(-1) # autotune \n",
        "    return dataset\n",
        "\n",
        "train_input_fn = partial(data_input_fn,FLAGS=FLAGS)\n",
        "\n",
        "def serving_input_fn():\n",
        "    inputs = {\"serving_input\": tf.placeholder(tf.float32,[None,FLAGS.IMAGE_DIM,FLAGS.IMAGE_DIM,FLAGS.NB_CHANNELS])}  \n",
        "    features = inputs['serving_input']  \n",
        "    return tf.estimator.export.TensorServingInputReceiver(features, inputs)  \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpOa3ff8CUQd",
        "colab_type": "text"
      },
      "source": [
        "#### TPU config and estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5oLMVL9CZnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        " \n",
        "TPU = tf.contrib.cluster_resolver.TPUClusterResolver()\n",
        " \n",
        "config = tf.contrib.tpu.RunConfig(\n",
        "                                   cluster=TPU,\n",
        "                                   model_dir=MODEL_DIR,\n",
        "                                   tpu_config=tf.contrib.tpu.TPUConfig(STEPS)\n",
        "                                   )\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "                                        model_fn=model_fn,\n",
        "                                        model_dir=MODEL_DIR,\n",
        "                                        train_batch_size=FLAGS.BATCH_SIZE,\n",
        "                                        config=config,\n",
        "                                        use_tpu=True,\n",
        "                                        export_to_tpu=False\n",
        "                                        )  \n",
        "# we want an exported model for CPU/GPU inference \n",
        "estimator.train(train_input_fn, steps=STEPS*FLAGS.ITERATIONS)\n",
        "estimator.export_savedmodel(os.path.join(MODEL_DIR, MODEL_EXPORT_NAME), serving_input_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
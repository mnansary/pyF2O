{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "pix2pix.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mnansary/pyF2O/blob/master/colab_gen_unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1ojVYZ7Spzpv"
      },
      "source": [
        "# colab specific task\n",
        "*   Check TF version\n",
        "*   mount google drive\n",
        "*   TPU check\n",
        "*   Change Working Directory to cloned dir \n",
        "\n",
        "NOTE: **git clone the repo before running this notebook**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "--q4JaV2ps6z",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9NVN35lELc_p",
        "colab": {}
      },
      "source": [
        "\n",
        "# tpu check\n",
        "import os\n",
        "import pprint\n",
        "import tensorflow as tf\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "    devices = session.list_devices()\n",
        "    \n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(devices)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHqKojwYNT58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/gdrive/My\\ Drive/PROJECTS/F2O/pyF2O/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_HoJM2SopemQ"
      },
      "source": [
        "# GCS specific task \n",
        "* **auth user**\n",
        "* **save** and **upload** credentials to **tpu**\n",
        "* set project information\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cAxBhxEtlLm9",
        "colab": {}
      },
      "source": [
        "# auth user for cloud SDK\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O-JJkYZILgmi",
        "colab": {}
      },
      "source": [
        "# Save credentials\n",
        "import json\n",
        "SERVICE_KEY_PATH='/content/adc.json' # @param\n",
        "# Upload credentials to TPU.\n",
        "with tf.Session(TPU_ADDRESS) as sess:    \n",
        "    with open(SERVICE_KEY_PATH, 'r') as f:\n",
        "        auth_info = json.load(f)\n",
        "        tf.contrib.cloud.configure_gcs(sess, credentials=auth_info)\n",
        "# set service_account\n",
        "JSON_DATA=json.load(open(SERVICE_KEY_PATH))\n",
        "SERVICE_ACCOUNT=str(JSON_DATA['client_id']).split('.')[0]\n",
        "print('Service Account:',SERVICE_ACCOUNT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E0MQ_8RgO4Qi"
      },
      "source": [
        "#### SET PROJECT INFORMATION "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4pCaaRGjLRmz",
        "outputId": "07ab27f9-ad10-424c-a8b8-05708e7c07b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "PROJECT_ID    ='f2oitpu'               # @param \n",
        "BUCKET        ='f2odata'               # @param \n",
        "\n",
        "# LIST FILES\n",
        "TFRECORDS_DIR= 'gs://{}/{}/'.format(BUCKET,'tfrecord')\n",
        "MODEL_DIR    = 'gs://{}/{}/'.format(BUCKET,'model_dir')\n",
        "# change TFRECORDS_DIR specific to structre\n",
        "#\n",
        "!gcloud config set project {PROJECT_ID}\n",
        "!gsutil ls {TFRECORDS_DIR}\n",
        "!gsutil ls gs://{BUCKET}\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "gs://f2odata/tfrecord/test/\n",
            "gs://f2odata/tfrecord/train/\n",
            "gs://f2odata/model_dir/\n",
            "gs://f2odata/tfrecord/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dxefiHZ4qlHA"
      },
      "source": [
        "# pix2pix\n",
        "* set **FLAGS** \n",
        "* define **model function**\n",
        "* define **input function**\n",
        "* define **config**\n",
        "* define **estimator**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FRPtSIGWin7u"
      },
      "source": [
        "#### FLAGS AND PARAMS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BOro7D1krWYf",
        "outputId": "cb6f5c50-e0f3-408c-a16d-0b5b84f9c5e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class FLAGS:\n",
        "    IMAGE_DIM       = 256       # @param\n",
        "    NB_CHANNELS     = 3         # @param\n",
        "    BATCH_SIZE      = 128       # @param\n",
        "    SHUFFLE_BUFFER  = 1000      # @param    \n",
        "    NB_TOTAL_DATA   = 16128     # @param\n",
        "    NB_EVAL_DATA    = 3200      # @param\n",
        "    ITERATIONS      = 1       # @param\n",
        "    LEARNING_RATE   = 0.0002    # @param\n",
        "\n",
        "MODEL_EXPORT_NAME = 'f20pix2pix' # @param\n",
        "STEPS           = FLAGS.NB_TOTAL_DATA // FLAGS.BATCH_SIZE \n",
        "print('Num of Steps:{}'.format(STEPS))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num of Steps:126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQO3uJ6KN3W3",
        "colab_type": "text"
      },
      "source": [
        "#### Model Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZb95zZjN_yu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from F2O.pix2pix import loss_fn,generator_fn\n",
        "\n",
        "def model_fn(features, labels, mode, params):\n",
        "    \n",
        "    if (mode != tf.estimator.ModeKeys.PREDICT):\n",
        "        \n",
        "        loss = loss_fn(features, labels)\n",
        "        \n",
        "        learning_rate = tf.train.exponential_decay(FLAGS.LEARNING_RATE,\n",
        "                                                   tf.train.get_global_step(),\n",
        "                                                   decay_steps=100000,\n",
        "                                                   decay_rate=0.96)\n",
        "        \n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "        \n",
        "        optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\n",
        "        \n",
        "        train_op=optimizer.minimize(loss,\n",
        "                                    tf.train.get_global_step())\n",
        "        return tf.contrib.tpu.TPUEstimatorSpec(mode=mode,\n",
        "                                               loss=loss,\n",
        "                                               train_op=train_op)\n",
        "    else:\n",
        "        \n",
        "        predictions=generator_fn(features)\n",
        "\n",
        "        return tf.contrib.tpu.TPUEstimatorSpec(mode=mode,\n",
        "                                               predictions={\"predictions\": predictions})   \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6C3FkEX-iu9n"
      },
      "source": [
        "#### Data Input Functions\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yjBH4t36PydC",
        "outputId": "a860436b-8449-4ea6-8d5e-b12c83e6851f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.cloud import storage\n",
        "from functools import partial\n",
        "\n",
        "client = storage.Client(PROJECT_ID)\n",
        "# get bucket from the project\n",
        "bucket=client.get_bucket(BUCKET)\n",
        "print(bucket)\n",
        "\n",
        "def data_input_fn(FLAGS,mode,params): \n",
        "    \n",
        "    def _parser(example):\n",
        "        feature ={  'image'  : tf.io.FixedLenFeature([],tf.string) ,\n",
        "                    'target' : tf.io.FixedLenFeature([],tf.string)\n",
        "        }    \n",
        "        parsed_example=tf.io.parse_single_example(example,feature)\n",
        "        image_raw=parsed_example['image']\n",
        "        image=tf.image.decode_png(image_raw,channels=FLAGS.NB_CHANNELS)\n",
        "        image=tf.cast(image,tf.float32)/255.0\n",
        "        image=tf.reshape(image,(FLAGS.IMAGE_DIM,FLAGS.IMAGE_DIM,FLAGS.NB_CHANNELS))\n",
        "        \n",
        "        target_raw=parsed_example['target']\n",
        "        target=tf.image.decode_png(target_raw,channels=FLAGS.NB_CHANNELS)\n",
        "        target=tf.cast(target,tf.float32)/255.0\n",
        "        target=tf.reshape(target,(FLAGS.IMAGE_DIM,FLAGS.IMAGE_DIM,FLAGS.NB_CHANNELS))\n",
        "        return image,target\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset([os.path.join('gs://{}/'.format(BUCKET), f.name) for f in bucket.list_blobs(prefix='tfrecord/{}'.format(mode))])\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.shuffle(FLAGS.SHUFFLE_BUFFER,reshuffle_each_iteration=True)\n",
        "    dataset = dataset.map(_parser)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(FLAGS.BATCH_SIZE,drop_remainder=True)\n",
        "    dataset = dataset.prefetch(-1) # autotune    \n",
        "    return dataset\n",
        "\n",
        "train_input_fn = partial(data_input_fn,FLAGS=FLAGS,mode='train')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Bucket: f2odata>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmLQOxhDb6ff",
        "colab_type": "text"
      },
      "source": [
        "#### SERVING FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTYfFTygb_KL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def serving_input_receiver_fn(FLAGS):\n",
        "\n",
        "  def decode_parser(example):\n",
        "        feature ={  'image'  : tf.io.FixedLenFeature([],tf.string) ,\n",
        "                    'target' : tf.io.FixedLenFeature([],tf.string)\n",
        "        }    \n",
        "        parsed_example=tf.io.parse_single_example(example,feature)\n",
        "        image_raw=parsed_example['image']\n",
        "        image=tf.image.decode_png(image_raw,channels=FLAGS.NB_CHANNELS)\n",
        "        image=tf.cast(image,tf.float32)/255.0\n",
        "        image=tf.reshape(image,(FLAGS.IMAGE_DIM,FLAGS.IMAGE_DIM,FLAGS.NB_CHANNELS))      \n",
        "        return image\n",
        "  tensor = tf.placeholder(tf.float32,shape=[None])\n",
        "  data   = tf.map_fn(decode_parser,tensor)                           \n",
        "  return tf.estimator.export.ServingInputReceiver({'data': data},{'tensor': tensor})\n",
        "  \n",
        "serving_input_fn = partial(serving_input_receiver_fn,FLAGS=FLAGS)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpOa3ff8CUQd",
        "colab_type": "text"
      },
      "source": [
        "#### TPU config and estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5oLMVL9CZnS",
        "colab_type": "code",
        "outputId": "dbefcfda-2790-4ef2-b632-2e6d7833a334",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        " \n",
        "TPU = tf.contrib.cluster_resolver.TPUClusterResolver()\n",
        " \n",
        "config = tf.contrib.tpu.RunConfig(\n",
        "                                   cluster=TPU,\n",
        "                                   model_dir=MODEL_DIR,\n",
        "                                   tpu_config=tf.contrib.tpu.TPUConfig(STEPS)\n",
        "                                   )\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "                                        model_fn=model_fn,\n",
        "                                        model_dir=MODEL_DIR,\n",
        "                                        train_batch_size=FLAGS.BATCH_SIZE,\n",
        "                                        predict_batch_size=FLAGS.BATCH_SIZE,\n",
        "                                        config=config,\n",
        "                                        use_tpu=True,\n",
        "                                        export_to_tpu=False\n",
        "                                        )  \n",
        "# we want an exported model for CPU/GPU inference \n",
        "estimator.train(train_input_fn, steps=STEPS*FLAGS.ITERATIONS)\n",
        "estimator.export_savedmodel(os.path.join(MODEL_DIR, MODEL_EXPORT_NAME), serving_input_fn)\n",
        "tf_logging.set_verbosity(tf_logging.WARN)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7f7010af9d08>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://f2odata/model_dir/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.68.200.2:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f705fd27470>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.68.200.2:8470', '_evaluation_master': 'grpc://10.68.200.2:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=126, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f700f8c4c18>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.68.200.2:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 7705566064591269240)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 15085908907081167049)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 8480877223578042849)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 2970518992690438380)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 6056576763631769380)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 13592574305131241602)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 3638896716774357146)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 4690511752516453694)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 15869361158227129070)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 8709814332409355262)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 12621786214651058905)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/PROJECTS/F2O/pyF2O/F2O/pix2pix.py:98: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/PROJECTS/F2O/pyF2O/F2O/pix2pix.py:164: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://f2odata/model_dir/model.ckpt-1134\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 1134 into gs://f2odata/model_dir/model.ckpt.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:751: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 7 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Enqueue next (126) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (126) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 66)\n",
            "INFO:tensorflow:loss = 6.6686015, step = 1260\n",
            "INFO:tensorflow:Saving checkpoints for 1260 into gs://f2odata/model_dir/model.ckpt.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:Loss for final step: 6.6686015.\n",
            "INFO:tensorflow:training_loop marked as finished\n",
            "WARNING:tensorflow:From <ipython-input-11-c180389c0545>:21: Estimator.export_savedmodel (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function has been renamed, use `export_saved_model` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    529\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1272\u001b[0m           \u001b[0;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1273\u001b[0;31m           (dtype.name, value.dtype.name, value))\n\u001b[0m\u001b[1;32m   1274\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype string for Tensor with dtype float32: <tf.Tensor 'map/while/TensorArrayReadV3:0' shape=() dtype=float32>",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c180389c0545>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# we want an exported model for CPU/GPU inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEPS\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_savedmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_EXPORT_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserving_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mtf_logging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_logging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWARN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mexport_savedmodel\u001b[0;34m(self, export_dir_base, serving_input_receiver_fn, assets_extra, as_text, checkpoint_path, strip_default_attrs)\u001b[0m\n\u001b[1;32m   1716\u001b[0m         \u001b[0mas_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m         \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1718\u001b[0;31m         strip_default_attrs=strip_default_attrs)\n\u001b[0m\u001b[1;32m   1719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_export_all_saved_models\u001b[0;34m(self, export_dir_base, input_receiver_fn_map, assets_extra, as_text, checkpoint_path, strip_default_attrs)\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_receiver_fn_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0msave_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             strip_default_attrs=strip_default_attrs)\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0msave_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36m_add_meta_graph_for_mode\u001b[0;34m(self, builder, input_receiver_fn_map, checkpoint_path, save_variables, mode, export_tags, check_variables, strip_default_attrs)\u001b[0m\n\u001b[1;32m   2825\u001b[0m           \u001b[0mexport_tags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexport_tags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m           \u001b[0mcheck_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_variables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2827\u001b[0;31m           strip_default_attrs=strip_default_attrs))\n\u001b[0m\u001b[1;32m   2828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2829\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_export_to_tpu\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_add_meta_graph_for_mode\u001b[0;34m(self, builder, input_receiver_fn_map, checkpoint_path, save_variables, mode, export_tags, check_variables, strip_default_attrs)\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0mrandom_seed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_random_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m       \u001b[0minput_receiver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_receiver_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m       \u001b[0;31m# Call the model_fn and collect the export_outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-a46157aeeccc>\u001b[0m in \u001b[0;36mserving_input_receiver_fn\u001b[0;34m(FLAGS)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mdata\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_parser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServingInputReceiver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'tensor'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/map_fn.py\u001b[0m in \u001b[0;36mmap_fn\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mback_prop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         maximum_iterations=n)\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0mresults_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2751\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2752\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 2753\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   2754\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2755\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   2243\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2245\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2246\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2168\u001b[0m         expand_composites=True)\n\u001b[1;32m   2169\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2170\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2171\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   2703\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   2704\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 2705\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2706\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/map_fn.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(i, tas)\u001b[0m\n\u001b[1;32m    255\u001b[0m       \"\"\"\n\u001b[1;32m    256\u001b[0m       \u001b[0mpacked_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_ta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem_ta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melems_ta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m       \u001b[0mpacked_fn_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m       \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacked_fn_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m       \u001b[0mflat_fn_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_fn_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-a46157aeeccc>\u001b[0m in \u001b[0;36mdecode_parser\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0;34m'target'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFixedLenFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         }    \n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mparsed_example\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_single_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mimage_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparsed_example\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNB_CHANNELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/parsing_ops.py\u001b[0m in \u001b[0;36mparse_single_example\u001b[0;34m(serialized, features, name, example_names)\u001b[0m\n\u001b[1;32m   1017\u001b[0m   \"\"\"\n\u001b[1;32m   1018\u001b[0m   return parse_single_example_v2_unoptimized(\n\u001b[0;32m-> 1019\u001b[0;31m       \u001b[0mserialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m       )\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/parsing_ops.py\u001b[0m in \u001b[0;36mparse_single_example_v2_unoptimized\u001b[0;34m(serialized, features, example_names, name)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Missing features.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mexample_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparse_single_example_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m   \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepend_none_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m   (sparse_keys, sparse_types, dense_keys, dense_types, dense_defaults,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/parsing_ops.py\u001b[0m in \u001b[0;36mparse_single_example_v2\u001b[0;34m(serialized, features, name)\u001b[0m\n\u001b[1;32m   2091\u001b[0m   outputs = _parse_single_example_v2_raw(serialized, sparse_keys, sparse_types,\n\u001b[1;32m   2092\u001b[0m                                          \u001b[0mdense_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2093\u001b[0;31m                                          dense_defaults, dense_shapes, name)\n\u001b[0m\u001b[1;32m   2094\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_construct_sparse_tensors_for_sparse_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/parsing_ops.py\u001b[0m in \u001b[0;36m_parse_single_example_v2_raw\u001b[0;34m(serialized, sparse_keys, sparse_types, dense_keys, dense_types, dense_defaults, dense_shapes, name)\u001b[0m\n\u001b[1;32m   2208\u001b[0m         \u001b[0mdense_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m         \u001b[0mdense_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0msparse_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_parsing_ops.py\u001b[0m in \u001b[0;36mparse_single_example\u001b[0;34m(serialized, dense_defaults, num_sparse, sparse_keys, dense_keys, sparse_types, dense_shapes, name)\u001b[0m\n\u001b[1;32m   1199\u001b[0m                               \u001b[0mdense_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m                               \u001b[0msparse_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m                               dense_shapes=dense_shapes, name=name)\n\u001b[0m\u001b[1;32m   1202\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtypes_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDT_INVALID\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m               raise TypeError(\"%s expected type of %s.\" %\n\u001b[0;32m--> 551\u001b[0;31m                               (prefix, dtypes.as_dtype(input_arg.type).name))\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m               \u001b[0;31m# Update the maps with the default, if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Input 'serialized' of 'ParseSingleExample' Op has type float32 that does not match expected type of string."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKfsUa-LF2bc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil -m cp -R gs://f2odata/model_dir /content/gdrive/My\\ Drive/PROJECTS/F2O/"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gen_unet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mnansary/pyF2O/blob/master/colab_gen_unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ojVYZ7Spzpv",
        "colab_type": "text"
      },
      "source": [
        "# colab specific task\n",
        "*   mount google drive\n",
        "*   TPU check\n",
        "*   Check TF version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--q4JaV2ps6z",
        "colab_type": "code",
        "outputId": "af1bfb05-f80b-428f-ff0e-7d7f006d7b5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NVN35lELc_p",
        "colab_type": "code",
        "outputId": "405feecd-0fce-44dd-cef9-858eb8f6b02e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "\n",
        "# tpu check\n",
        "import os\n",
        "import pprint\n",
        "import tensorflow as tf\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "    devices = session.list_devices()\n",
        "    \n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(devices)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.42.124.66:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 9360561929670052793),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 9631908168161504717),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 4283045023088742688),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 4476928320087680980),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 14323803195418573646),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 9045814018959949270),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 13455168068812267422),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 6502888340727842632),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 18112862821238392307),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 7810291220189162252),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 17537164398561542210)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EShrJafhedr",
        "colab_type": "code",
        "outputId": "d66b0e00-4029-4f79-b381-c213a36067c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "!pip3 install tensorflow==1.14.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.1.7)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.16.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.33.6)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.11.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.7.1)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (41.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HoJM2SopemQ",
        "colab_type": "text"
      },
      "source": [
        "# GCS specific task \n",
        "* **auth user**\n",
        "* **save** and **upload** credentials to **tpu**\n",
        "* set project information\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAxBhxEtlLm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# auth user for cloud SDK\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-JJkYZILgmi",
        "colab_type": "code",
        "outputId": "e0ff412a-f3a6-460b-f58c-5a4ca17e41b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "# Save credentials\n",
        "import json\n",
        "SERVICE_KEY_PATH='/content/adc.json' # @param\n",
        "# Upload credentials to TPU.\n",
        "with tf.Session(TPU_ADDRESS) as sess:    \n",
        "    with open(SERVICE_KEY_PATH, 'r') as f:\n",
        "        auth_info = json.load(f)\n",
        "        tf.contrib.cloud.configure_gcs(sess, credentials=auth_info)\n",
        "# set service_account\n",
        "JSON_DATA=json.load(open(SERVICE_KEY_PATH))\n",
        "SERVICE_ACCOUNT=str(JSON_DATA['client_id']).split('.')[0]\n",
        "print('Service Account:',SERVICE_ACCOUNT)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Service Account: 32555940559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0MQ_8RgO4Qi",
        "colab_type": "text"
      },
      "source": [
        "#### SET PROJECT INFORMATION "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pCaaRGjLRmz",
        "colab_type": "code",
        "outputId": "f5fd35bc-8627-4f83-cb57-29b4dbd0c255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "PROJECT_ID    ='f2oitpu'               # @param \n",
        "BUCKET        ='f2odata'               # @param \n",
        "\n",
        "# LIST FILES\n",
        "TFRECORDS_DIR= 'gs://{}/{}/'.format(BUCKET,'tfrecord')\n",
        "#\n",
        "# change TFRECORDS_DIR specific to structre\n",
        "#\n",
        "!gcloud config set project {PROJECT_ID}\n",
        "!gsutil ls {TFRECORDS_DIR}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "gs://f2odata/tfrecord/eval/\n",
            "gs://f2odata/tfrecord/train/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxefiHZ4qlHA",
        "colab_type": "text"
      },
      "source": [
        "# UNET generator Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blwtSzOarVYM",
        "colab_type": "text"
      },
      "source": [
        "## Data Pipeline\n",
        "* set FLAGS and PARAMS\n",
        "* define input functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRPtSIGWin7u",
        "colab_type": "text"
      },
      "source": [
        "#### FLAGS AND PARAMS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOro7D1krWYf",
        "colab_type": "code",
        "outputId": "45ed309a-2798-42ea-b836-e57d38e7c593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from glob import glob\n",
        "\n",
        "class FLAGS:\n",
        "    IMAGE_DIM       = 256 # @param\n",
        "    NB_CHANNELS     = 3   # @param\n",
        "    BATCH_SIZE      = 128 # @param\n",
        "    SHUFFLE_BUFFER  = 1000 # @param\n",
        "    \n",
        "NB_TOTAL_DATA       = 16128 # @param\n",
        "NB_EVAL_DATA        = 3200  # @param\n",
        "N_EPOCHS            = 10   # @param\n",
        "LEARNING_RATE       = 1e-2  # @param\n",
        "\n",
        "STEPS_PER_EPOCH     =  NB_TOTAL_DATA // FLAGS.BATCH_SIZE \n",
        "VALIDATION_STEPS    =  NB_EVAL_DATA  // FLAGS.BATCH_SIZE \n",
        "\n",
        "print('Steps Per epoch:',STEPS_PER_EPOCH)\n",
        "print('Validation Steps:', VALIDATION_STEPS)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps Per epoch: 126\n",
            "Validation Steps: 25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C3FkEX-iu9n",
        "colab_type": "text"
      },
      "source": [
        "#### Data Input Functions\n",
        "* get **bucket** \n",
        "* define **train_in_fn()** and **eval_in_fn()**\n",
        "* **NOTE:AVOID USING PARTIALS** \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjBH4t36PydC",
        "colab_type": "code",
        "outputId": "7de8f7bd-5498-4116-ff6e-fe616ce5f681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.cloud import storage\n",
        "client = storage.Client(PROJECT_ID)\n",
        "# get bucket from the project\n",
        "bucket=client.get_bucket(BUCKET)\n",
        "print(bucket)\n",
        "def data_input_fn(FLAGS,mode): \n",
        "    \n",
        "    def _parser(example):\n",
        "        feature ={  'image'  : tf.io.FixedLenFeature([],tf.string) ,\n",
        "                    'target' : tf.io.FixedLenFeature([],tf.string)\n",
        "        }    \n",
        "        parsed_example=tf.io.parse_single_example(example,feature)\n",
        "        image_raw=parsed_example['image']\n",
        "        image=tf.image.decode_png(image_raw,channels=FLAGS.NB_CHANNELS)\n",
        "        image=tf.cast(image,tf.float32)/255.0\n",
        "        image=tf.reshape(image,(FLAGS.IMAGE_DIM,FLAGS.IMAGE_DIM,FLAGS.NB_CHANNELS))\n",
        "        \n",
        "        target_raw=parsed_example['target']\n",
        "        target=tf.image.decode_png(target_raw,channels=FLAGS.NB_CHANNELS)\n",
        "        target=tf.cast(target,tf.float32)/255.0\n",
        "        target=tf.reshape(target,(FLAGS.IMAGE_DIM,FLAGS.IMAGE_DIM,FLAGS.NB_CHANNELS))\n",
        "        \n",
        "        return image,target\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset([os.path.join('gs://{}/'.format(BUCKET), f.name) for f in bucket.list_blobs(prefix='tfrecord/{}'.format(mode))])\n",
        "    dataset = dataset.shuffle(FLAGS.SHUFFLE_BUFFER,reshuffle_each_iteration=True)\n",
        "    dataset = dataset.map(_parser)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(FLAGS.BATCH_SIZE,drop_remainder=True)\n",
        "    return dataset\n",
        "\n",
        "def train_in_fn():\n",
        "  return data_input_fn(FLAGS,'train')\n",
        "def eval_in_fn():\n",
        "  return data_input_fn(FLAGS,'eval')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Bucket: f2odata>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIGSxPbFgwZh",
        "colab_type": "text"
      },
      "source": [
        "## Change to git repo dir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySSaUDNQgwBK",
        "colab_type": "code",
        "outputId": "6c09aeed-8899-4a0a-cafd-1cb295bfbe94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/gdrive/My\\ Drive/PROJECTS/F2O/pyF2O/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/PROJECTS/F2O/pyF2O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMWNlaqLNIPY",
        "colab_type": "text"
      },
      "source": [
        "## CREATE MODEL\n",
        "* **resolve** TPU cluster\n",
        "* define **strategy**\n",
        "* **compile** within **strategy scope**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WMdSlCZJPWi",
        "colab_type": "code",
        "outputId": "0245454c-21e6-480e-8ac2-339418297559",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow.keras.backend as K \n",
        "from F2O.generators import unet\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "resolver = tf.contrib.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
        "\n",
        "def patchLoss(y_true,y_pred):\n",
        "  thresh=0.31\n",
        "  weight_factor=1e-2\n",
        "  # image construction loss\n",
        "  back_loss=weight_factor*K.abs(y_true[y_true < thresh]-y_pred[y_true < thresh])\n",
        "  # manipulated region loss  \n",
        "  block_loss=K.abs(y_true[y_true >= thresh]-y_pred[y_true >= thresh]) \n",
        "  \n",
        "  patch_loss=back_loss+block_loss\n",
        "  \n",
        "  return tf.keras.layers.Activation('relu')(patch_loss) \n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "with strategy.scope():\n",
        "  model = unet(image_dim=FLAGS.IMAGE_DIM)\n",
        "  model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),loss=patchLoss)\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system.\n",
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.42.124.66:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 9360561929670052793)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 4283045023088742688)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 4476928320087680980)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 14323803195418573646)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 9045814018959949270)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 13455168068812267422)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 6502888340727842632)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 18112862821238392307)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 7810291220189162252)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 17537164398561542210)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 9631908168161504717)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "gen_enc_init_input (InputLayer) [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_1 (Conv2D)         (None, 128, 128, 64) 1792        gen_enc_init_input[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_2_act (LeakyReLU)  (None, 128, 128, 64) 0           gen_enc_conv_1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_2 (Conv2D)         (None, 64, 64, 128)  73856       gen_enc_conv_2_act[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_2_bn (BatchNormali (None, 64, 64, 128)  512         gen_enc_conv_2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_3_act (LeakyReLU)  (None, 64, 64, 128)  0           gen_enc_conv_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_3 (Conv2D)         (None, 32, 32, 256)  295168      gen_enc_conv_3_act[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_3_bn (BatchNormali (None, 32, 32, 256)  1024        gen_enc_conv_3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_4_act (LeakyReLU)  (None, 32, 32, 256)  0           gen_enc_conv_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_4 (Conv2D)         (None, 16, 16, 512)  1180160     gen_enc_conv_4_act[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_4_bn (BatchNormali (None, 16, 16, 512)  2048        gen_enc_conv_4[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_5_act (LeakyReLU)  (None, 16, 16, 512)  0           gen_enc_conv_4_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_5 (Conv2D)         (None, 8, 8, 512)    2359808     gen_enc_conv_5_act[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_5_bn (BatchNormali (None, 8, 8, 512)    2048        gen_enc_conv_5[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_6_act (LeakyReLU)  (None, 8, 8, 512)    0           gen_enc_conv_5_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_6 (Conv2D)         (None, 4, 4, 512)    2359808     gen_enc_conv_6_act[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_6_bn (BatchNormali (None, 4, 4, 512)    2048        gen_enc_conv_6[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_7_act (LeakyReLU)  (None, 4, 4, 512)    0           gen_enc_conv_6_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_7 (Conv2D)         (None, 2, 2, 512)    2359808     gen_enc_conv_7_act[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_7_bn (BatchNormali (None, 2, 2, 512)    2048        gen_enc_conv_7[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_8_act (LeakyReLU)  (None, 2, 2, 512)    0           gen_enc_conv_7_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_8 (Conv2D)         (None, 1, 1, 512)    2359808     gen_enc_conv_8_act[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "gen_enc_conv_8_bn (BatchNormali (None, 1, 1, 512)    2048        gen_enc_conv_8[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_conv_1_act (Activation) (None, 1, 1, 512)    0           gen_enc_conv_8_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_deconv_1 (Conv2DTranspo (None, 2, 2, 512)    2359808     gen_dec_conv_1_act[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_deconv_1_bn (BatchNorma (None, 2, 2, 512)    2048        gen_dec_deconv_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_deconv_1_conc (Concaten (None, 2, 2, 1024)   0           gen_dec_deconv_1_bn[0][0]        \n",
            "                                                                 gen_enc_conv_7_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_conv_2_act (Activation) (None, 2, 2, 1024)   0           gen_dec_deconv_1_conc[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_deconv_2 (Conv2DTranspo (None, 4, 4, 512)    4719104     gen_dec_conv_2_act[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_deconv_2_bn (BatchNorma (None, 4, 4, 512)    2048        gen_dec_deconv_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_deconv_2_conc (Concaten (None, 4, 4, 1024)   0           gen_dec_deconv_2_bn[0][0]        \n",
            "                                                                 gen_enc_conv_6_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_conv_3_act (Activation) (None, 4, 4, 1024)   0           gen_dec_deconv_2_conc[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_deconv_3 (Conv2DTranspo (None, 8, 8, 512)    4719104     gen_dec_conv_3_act[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_deconv_3_bn (BatchNorma (None, 8, 8, 512)    2048        gen_dec_deconv_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_deconv_3_conc (Concaten (None, 8, 8, 1024)   0           gen_dec_deconv_3_bn[0][0]        \n",
            "                                                                 gen_enc_conv_5_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_conv_4_act (Activation) (None, 8, 8, 1024)   0           gen_dec_deconv_3_conc[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_deconv_4 (Conv2DTranspo (None, 16, 16, 256)  2359552     gen_dec_conv_4_act[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_deconv_4_bn (BatchNorma (None, 16, 16, 256)  1024        gen_dec_deconv_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_deconv_4_conc (Concaten (None, 16, 16, 768)  0           gen_dec_deconv_4_bn[0][0]        \n",
            "                                                                 gen_enc_conv_4_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_conv_5_act (Activation) (None, 16, 16, 768)  0           gen_dec_deconv_4_conc[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_deconv_5 (Conv2DTranspo (None, 32, 32, 128)  884864      gen_dec_conv_5_act[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_deconv_5_bn (BatchNorma (None, 32, 32, 128)  512         gen_dec_deconv_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_deconv_5_conc (Concaten (None, 32, 32, 384)  0           gen_dec_deconv_5_bn[0][0]        \n",
            "                                                                 gen_enc_conv_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_conv_6_act (Activation) (None, 32, 32, 384)  0           gen_dec_deconv_5_conc[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_deconv_6 (Conv2DTranspo (None, 64, 64, 64)   221248      gen_dec_conv_6_act[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_deconv_6_bn (BatchNorma (None, 64, 64, 64)   256         gen_dec_deconv_6[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_deconv_6_conc (Concaten (None, 64, 64, 192)  0           gen_dec_deconv_6_bn[0][0]        \n",
            "                                                                 gen_enc_conv_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_conv_7_act (Activation) (None, 64, 64, 192)  0           gen_dec_deconv_6_conc[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_deconv_7 (Conv2DTranspo (None, 128, 128, 64) 110656      gen_dec_conv_7_act[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_deconv_7_bn (BatchNorma (None, 128, 128, 64) 256         gen_dec_deconv_7[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_deconv_7_conc (Concaten (None, 128, 128, 128 0           gen_dec_deconv_7_bn[0][0]        \n",
            "                                                                 gen_enc_conv_1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_conv_last_act (Activati (None, 128, 128, 128 0           gen_dec_deconv_7_conc[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_conv_last (Conv2DTransp (None, 256, 256, 3)  3459        gen_dec_conv_last_act[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "gen_dec_conv_final_act (Activat (None, 256, 256, 3)  0           gen_dec_conv_last[0][0]          \n",
            "==================================================================================================\n",
            "Total params: 26,387,971\n",
            "Trainable params: 26,377,987\n",
            "Non-trainable params: 9,984\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nQXx8YRNSyr",
        "colab_type": "text"
      },
      "source": [
        "## Train\n",
        "* define **checkpoints** and **callbacks** (tensorboard avoided)\n",
        "* train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWTUQlweNYYN",
        "colab_type": "code",
        "outputId": "d124c73e-16bb-476b-8f86-5a4c5e51deb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import h5py\n",
        "model_dir=os.path.join(os.getcwd(),'F2O','model_weights')\n",
        "model_name='uNet' # @param\n",
        "checkpoint = ModelCheckpoint(filepath=os.path.join(model_dir,'{}.h5'.format(model_name)), verbose=1, save_best_only=True)\n",
        "history =  model.fit(\n",
        "              train_in_fn(),\n",
        "              epochs= N_EPOCHS,\n",
        "              steps_per_epoch= STEPS_PER_EPOCH,\n",
        "              validation_data=eval_in_fn(),\n",
        "              validation_steps= VALIDATION_STEPS,\n",
        "              callbacks=[checkpoint],\n",
        "              verbose=1\n",
        "            )\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-9bbe2f1416f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m               \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mVALIDATION_STEPS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m             validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m     batch_size = self._validate_or_infer_batch_size(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py\u001b[0m in \u001b[0;36mfit_distributed\u001b[0;34m(model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m    129\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     return training_arrays.fit_loop(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py\u001b[0m in \u001b[0;36mexperimental_tpu_fit_loop\u001b[0;34m(model, dataset, epochs, verbose, callbacks, initial_epoch, steps_per_epoch, val_dataset, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    365\u001b[0m   ctx = current_strategy.extended.experimental_run_steps_on_iterator(\n\u001b[1;32m    366\u001b[0m       \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_run\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m       initial_loop_values=initial_loop_values)\n\u001b[0m\u001b[1;32m    368\u001b[0m   \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m   \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_step_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_steps_on_iterator\u001b[0;34m(self, fn, iterator, iterations, initial_loop_values)\u001b[0m\n\u001b[1;32m   1499\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m       return self._experimental_run_steps_on_iterator(fn, iterator, iterations,\n\u001b[0;32m-> 1501\u001b[0;31m                                                       initial_loop_values)\n\u001b[0m\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m   def _experimental_run_steps_on_iterator(self, fn, iterator, iterations,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py\u001b[0m in \u001b[0;36m_experimental_run_steps_on_iterator\u001b[0;34m(self, fn, multi_worker_iterator, iterations, initial_loop_values)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_host_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_run\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mreplicate_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewrite_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         replicate_outputs = training_loop.repeat(iterations, rewrite_fn,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py\u001b[0m in \u001b[0;36mrewrite_fn\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    395\u001b[0m             select_replica, per_replica_inputs),))\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m       \u001b[0mreplicate_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicate_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m       \u001b[0;31m# If run_fn has tensor outputs, tpu.replicate returns a list of list. We\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/tpu/tpu.py\u001b[0m in \u001b[0;36mreplicate\u001b[0;34m(computation, inputs, infeed_queue, device_assignment, name, maximum_shapes)\u001b[0m\n\u001b[1;32m    590\u001b[0m       \u001b[0mdevice_assignment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m       maximum_shapes=maximum_shapes)[1]\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/tpu/tpu.py\u001b[0m in \u001b[0;36msplit_compile_and_replicate\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mvscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_custom_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcomputation_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m       \u001b[0mvscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_use_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_use_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py\u001b[0m in \u001b[0;36mrun_fn\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m       \u001b[0;34m\"\"\"Single step on the TPU device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m       \u001b[0mfn_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m       \u001b[0mflat_last_step_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_step_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mflat_last_step_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py\u001b[0m in \u001b[0;36m_step_fn\u001b[0;34m(ctx, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[0m_build_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     (grouped_inputs, grouped_outputs, grouped_updates,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py\u001b[0m in \u001b[0;36m_build_model\u001b[0;34m(strategy, model, mode, inputs, targets)\u001b[0m\n\u001b[1;32m    222\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     distributed_training_utils._build_distributed_network(\n\u001b[0;32m--> 224\u001b[0;31m         model, strategy, mode, inputs, targets)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/distribute/distributed_training_utils.py\u001b[0m in \u001b[0;36m_build_distributed_network\u001b[0;34m(model, strategy, mode, inputs, targets)\u001b[0m\n\u001b[1;32m    719\u001b[0m     distributed_model = strategy.extended.call_for_each_replica(\n\u001b[1;32m    720\u001b[0m         \u001b[0m_build_network_on_replica\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         args=(model, mode, inputs, targets))\n\u001b[0m\u001b[1;32m    722\u001b[0m     \u001b[0mset_distributed_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0;31m# we're in a tpu.rewrite(), and update TPUMirroredVariable accordingly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_TPUReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_experimental_initialize_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/distribute/distributed_training_utils.py\u001b[0m in \u001b[0;36m_build_network_on_replica\u001b[0;34m(model, mode, inputs, targets)\u001b[0m\n\u001b[1;32m    709\u001b[0m         weighted_metrics=metrics_module.clone_metrics(\n\u001b[1;32m    710\u001b[0m             model._compile_weighted_metrics),\n\u001b[0;32m--> 711\u001b[0;31m         target_tensors=targets)\n\u001b[0m\u001b[1;32m    712\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mupdated_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m       \u001b[0;31m# Creates the model loss and weighted metrics sub-graphs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_weights_loss_and_weighted_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m       \u001b[0;31m# Functions for train, test and predict will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_compile_weights_loss_and_weighted_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1708\u001b[0m       \u001b[0;31m#                   loss_weight_2 * output_2_loss_fn(...) +\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m       \u001b[0;31m#                   layer losses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1710\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_total_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_skip_target_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_prepare_total_loss\u001b[0;34m(self, masks)\u001b[0m\n\u001b[1;32m   1768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reduction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1770\u001b[0;31m             \u001b[0mper_sample_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1771\u001b[0m             weighted_losses = losses_utils.compute_weighted_loss(\n\u001b[1;32m   1772\u001b[0m                 \u001b[0mper_sample_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    213\u001b[0m       \u001b[0mLoss\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \"\"\"\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-ef265c87bcc6>\u001b[0m in \u001b[0;36mpatchLoss\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mpatch_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mback_loss\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mblock_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m       \u001b[0;31m# framework.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_keras_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_keras_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;31m# Handle Keras mask propagation from previous layer to current layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mcreate_keras_history\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0mkeras_tensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mTensors\u001b[0m \u001b[0mfound\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcame\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0ma\u001b[0m \u001b[0mKeras\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m   \"\"\"\n\u001b[0;32m--> 200\u001b[0;31m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreated_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_keras_history_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcreated_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mconstants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n\u001b[0;32m--> 246\u001b[0;31m           layer_inputs, processed_ops, created_layers)\n\u001b[0m\u001b[1;32m    247\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m       \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mconstants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mconstants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n\u001b[1;32m    246\u001b[0m           layer_inputs, processed_ops, created_layers)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3251\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3253\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3254\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3255\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    460\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[0;31m# marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m     is_initialized = session.run(\n\u001b[0;32m--> 879\u001b[0;31m         [variables_module.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    880\u001b[0m     \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1158\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_fetchable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_assert_fetchable\u001b[0;34m(self, graph, op)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fetchable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m       raise ValueError(\n\u001b[0;32m--> 500\u001b[0;31m           'Operation %r has been marked as not fetchable.' % op.name)\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Operation 'loss_1/gen_dec_conv_final_act_loss/VarIsInitializedOp' has been marked as not fetchable."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1M9sjHIbSnf",
        "colab_type": "text"
      },
      "source": [
        "#### Plot Training Histoty"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndNSS7XIbXaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('LOSS History')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.savefig(os.path.join(model_dir,'{}_history.png'.format(model_name)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}